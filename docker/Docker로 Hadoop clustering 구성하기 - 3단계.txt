원숭이도 할 수 있는 도커를 이용하여 하둡 클러스터 구성하기!!!

3단계에서는 Dockerfile을 이용하여 컨테이너의 설정을 자동화 방법을 통해 컨테이너를 만들고 실행한다.


***********************************************************************************************************************


일단 전체 컨테이너를 깔끔하게 지운다.


-----------------------------------------------------------------------------------------------------------------------
$ docker rm $(docker ps -a -q)
-----------------------------------------------------------------------------------------------------------------------


Dockerfile 파일 예시


-----------------------------------------------------------------------------------------------------------------------
Dockerfile
-----------------------------------------------------------------------------------------------------------------------
FROM ubuntu
RUN apt-get update
RUN apt-get install -y curl
RUN apt-get install -y nginx
(...)
FROM ubuntu
RUN apt-get update && apt-get install -y curl nginx
-----------------------------------------------------------------------------------------------------------------------
FROM 뒤의 레이어를 기반으로 도커를 실행한다.  태그를 쓰지 않으면 latest 를 이용한다.

RUN 을 실행할 때 마다 layer 가 하나씩 생긴다.  한번 설치된 레이어는 다시 실행되지 않으므로 위의 도커 파일을 재실행 하게 되면 
apt-get update 은 건너 뛴다.  RUN 하나에 && 를 써주게 되면 항상 같이 실행이 된다.

두번째 예제에서는 update 후 curl 과 nginx 가 같이 설치된다.
-----------------------------------------------------------------------------------------------------------------------


-----------------------------------------------------------------------------------------------------------------------
Dockerfile
-----------------------------------------------------------------------------------------------------------------------
FROM ubuntu
ENV JAVA_HONE /usr/local/java
ADD ./core-site.xml /usr/local/hadoop
ENTRYPOINT ["/bin/echo"]
CMD ["Hello", "World"]
(...)
Hello World
-----------------------------------------------------------------------------------------------------------------------
ENV 는 컨테이너의 환경변수를 설정한다.

ADD 는 호스트에 있는 파일을 컨테이너 내부로 전달한다.

ENTRYPOINT 와 CMD 둘 다 컨테이너 기동시에 실행될 명령어를 전달하는 기능을 한다.  단, ENTRYPOINT 는 컨테이너가 실행될 때 반드시
실행되는 반면에 CMD 는 만약 컨테이너 실행시에 인자값이 주어지면 지정한 인자값으로 변경이 되게 된다.  즉, 컨테이너 실행시의 
default 역할을 한다.
-----------------------------------------------------------------------------------------------------------------------


이제 실제로 도커 파일을 이용하여 이미지를 만들어서 3개의 노드로 구성된 하둡 클러스터를 구성해 본다.  베이스는 ubuntu 로 하고 


-----------------------------------------------------------------------------------------------------------------------
Dockerfile
-----------------------------------------------------------------------------------------------------------------------
FROM ubuntu

RUN apt-get update
RUN apt-get install openjdk-8-jdk -y
RUN apt-get install wget -y
RUN apt-get install vim -y
RUN apt-get install ssh -y

RUN mkdir    /hadoop_home
RUN wget -P  /hadoop_home http://mirrors.sonic.net/apache/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz
RUN tar xvzf /hadoop_home/hadoop-2.7.7.tar.gz  -C /hadoop_home

RUN ssh-keygen -t rsa -P '' -f ~/.ssh/id_dsa        && \
    cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys && \
    mkdir /var/run/sshd

ENV JAVA_HOME    /usr/lib/jvm/java-8-openjdk-amd64
ENV HADOOP_HOME  /hadoop_home/hadoop-2.7.7
ENV PATH         $PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

RUN mkdir /hadoop_home/temp
RUN mkdir /hadoop_home/namenode_home
RUN mkdir /hadoop_home/datanode_home
RUN echo "export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh 

ADD ./core-site.xml   $HADOOP_HOME/etc/hadoop
ADD ./hdfs-site.xml   $HADOOP_HOME/etc/hadoop
ADD ./mapred-site.xml $HADOOP_HOME/etc/hadoop

EXPOSE 9000 50010 50020 50030 50060 50070 50075 50090
-----------------------------------------------------------------------------------------------------------------------
도커 이미지는 레이어 단위로 설정이 된다.  따라서 &&로 연결되어 하나의 레이어로 묶인 커맨드의 경우에는 한 부분이 바뀌게 되면
해당 레이어가 다시 설치가 된다.  따라서 의존성이 없는 레이어의 경우에는 각각의 커맨드로 분리하는 것이 좋다.  또한 설치가 오래
걸리거나 한번 설치하면 수정할 사항이 거의 없는 레이어는 가급적 앞쪽에 배치하여 쓸데없이 재설치가 안되도록 관리한다.
-----------------------------------------------------------------------------------------------------------------------


완성된 도커 파일이용하여 아래의 명령어로 이미지를 만든다.


-----------------------------------------------------------------------------------------------------------------------
core-site.xml
hdfs-site.xml
mapred-site.xml
(...)
$ docker build -t ubuntu:hadoop .
-----------------------------------------------------------------------------------------------------------------------
-t ubuntu:hadoop : 이미지이름(REPOSITORY 로 표현)[:태그]
.                : Dockerfile 위치
이미지 내부로 전달할 하둡 설정파일은 Dockerfile 내부의 ADD 명령어에서 경로를 맞춰준다.
-----------------------------------------------------------------------------------------------------------------------


완성된 이미지를 이용하여 하둡 클러스터를 구성한다.  컨테이너간의 네트워크는 브릿지를 이용하며
컨테이너는 가상의 고정IP 사용하도록 한다.


-----------------------------------------------------------------------------------------------------------------------
$ docker network create --driver=bridge --ip-range=172.1.0.0/24 --subnet=172.1.0.0/24 hadoop_brigde
$ docker run -it --rm -h master --name master --network hadoop_brigde --ip 172.1.0.11 -p 9000:9000 -p 50010:50010 -p 50020:50020 -p 50030:50030 -p 50060:50060 -p 50070:50070 -p 50075:50075 -p 50090:50090 ubuntu:hadoop
$ docker run -it --rm -h slave1 --name slave1 --network hadoop_brigde --ip 172.1.0.12 ubuntu:hadoop
$ docker run -it --rm -h slave2 --name slave2 --network hadoop_brigde --ip 172.1.0.13 ubuntu:hadoop
$ docker run -it --rm -h client --name client --network hadoop_brigde --ip 172.1.0.14 ubuntu:hadoop
-----------------------------------------------------------------------------------------------------------------------
--rm : 컨테이너 종료 후 자동삭제
-----------------------------------------------------------------------------------------------------------------------


실행된 컨테이너를 각각의 역할에 맞게 설정해 주어야 하는데, 이 부분은 향후 docker-compose 와 swarm 사용시 자동화 할 것이다.
일단은 각각의 컨테이너를 수동으로 설정한다.


-----------------------------------------------------------------------------------------------------------------------
master
-----------------------------------------------------------------------------------------------------------------------
# vi /etc/hosts
172.1.0.11      master
172.1.0.12      slave1
172.1.0.13      slave2

#vi $HADOOP_HOME/etc/hadoop/slaves
slave1
slave2
master
-----------------------------------------------------------------------------------------------------------------------
데이터 노드로 사용할 호스트를 지정한다.  slave1, slave2 그리고 master 자기 자신도 데이터 노드로 사용한다.
-----------------------------------------------------------------------------------------------------------------------


ssh 사용을 위해 각각의 ssh 데몬을 띄원준다.  데몬 실행 후 root@slave1, root@slaves2 로 ssh 작동 여부를 확인한다.


-----------------------------------------------------------------------------------------------------------------------
master, slave1, slave2
-----------------------------------------------------------------------------------------------------------------------
# /usr/sbin/sshd
-----------------------------------------------------------------------------------------------------------------------


네임 노드를 포맷한다.


-----------------------------------------------------------------------------------------------------------------------
master
-----------------------------------------------------------------------------------------------------------------------
# hadoop namenode -format
-----------------------------------------------------------------------------------------------------------------------


실행 테스트


-----------------------------------------------------------------------------------------------------------------------
# docker run -it -h client --name client --link master:master ubuntu:hadoop
# cd $HADOOP_HOME
# hadoop fs -mkdir -p /test
# hadoop fs -put LICENSE.txt /test
# hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar wordcount /test /test_out

(MapReduce 실행...)

# hadoop fs -cat /test_out/*
# hadoop fs -ls /test_out

http://master:50070/
-----------------------------------------------------------------------------------------------------------------------
