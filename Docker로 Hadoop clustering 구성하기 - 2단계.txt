원숭이도 할 수 있는 도커를 이용하여 하둡 클러스터 구성하기!!!

2단계에서는 컨테이너간 네트워크로 link 옵션 대신 docker network 를 이용하고 컨테이너 가상IP를 고정IP로 하여 클러스터를 구성해 본다.

이미지는 1단계에서 사용한 이미지를 계속 사용한다.


***********************************************************************************************************************


일단 전체 컨테이너를 깔끔하게 지운다.


-----------------------------------------------------------------------------------------------------------------------
$ docker rm $(docker ps -a -q)
-----------------------------------------------------------------------------------------------------------------------


도커 브릿지 네크워크를 생성한다.



-----------------------------------------------------------------------------------------------------------------------
$ docker network ls
$ docker network create --driver=bridge --ip-range=172.1.0.0/24 --subnet=172.1.0.0/24 hadoop_brigde
-----------------------------------------------------------------------------------------------------------------------
--driver=bridge         : 브릿지 형태의 네트워크 드라이버를 설정
--ip-range=172.1.0.0/24 : 컨테이너들에게 할당 가능한 ip 범위
                          8*3=24 이므로 앞의 3개(172.1.0) 을 제외한 1 ~ 254 까지 할당이 가능하다.
--subnet=172.1.0.0/24   : 호스트와 실제 ip 대역을 마스킹 함으로써 네트워킹 속도를 높힌다.  즉, 라우팅 할때 172.1.0 는 주소
                          범위에 해당하지 않게 마스킹 한다.  ip-range 와 범위가 같아야 한다.
-----------------------------------------------------------------------------------------------------------------------


설정한 브릿지를 이용하여 컨테이너를 run 한다.


-----------------------------------------------------------------------------------------------------------------------
$ docker run -it -h master --name master --network hadoop_brigde --ip 172.1.0.10 -p 9000:9000 -p 50010:50010 -p 50020:50020 -p 50030:50030 -p 50060:50060 -p 50070:50070 -p 50075:50075 -p 50090:50090 ubuntu:hadoop
$ docker run -it -h slave1 --name slave1 --network hadoop_brigde --ip 172.1.0.11 --link master:master ubuntu:hadoop
$ docker run -it -h slave2 --name slave2 --network hadoop_brigde --ip 172.1.0.12 --link master:master ubuntu:hadoop
$ docker run -it -h client --name client --network hadoop_brigde --ip 172.1.0.13 --link master:master ubuntu:hadoop
-----------------------------------------------------------------------------------------------------------------------


각 컨테이너 IP 를 조사해 보면...


-----------------------------------------------------------------------------------------------------------------------
$ docker inspect master | findstr "IPAddress" => "IPAddress": "172.1.0.10"
$ docker inspect slave1 | findstr "IPAddress" => "IPAddress": "172.1.0.11"
$ docker inspect slave2 | findstr "IPAddress" => "IPAddress": "172.1.0.12"
$ docker inspect client | findstr "IPAddress" => "IPAddress": "172.1.0.13"
-----------------------------------------------------------------------------------------------------------------------


컨테이너를 시작할 때 지정한 ip 로 셋팅되어 있음을 알 수 있다.


1단계와 마찬가지로 마스터 컨테이너의 /etc/hosts, hdfs-site.xml, slaves 수정 후 start-all.sh 로 하둡을 실행시키고 테스트를 진행한다.
